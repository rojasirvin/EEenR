---
title: "Modelos lineales"
author: "Irvin Rojas"
date: "12 de febrero de 2021"
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{shapes, shadows,arrows}
output:
  xaringan::moon_reader:
    css: [default, "libs/cide.css", metropolis-fonts, "https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css", "https://use.fontawesome.com/releases/v5.7.2/css/all.css", "https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"]
    seal: false
    chakra: "https://remarkjs.com/downloads/remark-latest.min.js"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["middle", "center"]
      ratio: "16:9"
      beforeInit: ["https://platform.twitter.com/widgets.js", "libs/cols_macro.js"]
      navigation:
        scroll: false
---

class: title-slide

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.path = "figures/")
library(tidyverse)
library(magick)
library(reticulate)
xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))
```

.title[
# Sesión 10. Modelos lineales
]

.subtitle[
## Estadística y Econometría en R
]

.author[
### Irvin Rojas <br> [rojasirvin.com](https://www.rojasirvin.com/) <br> [<i class="fab fa-github"></i>](https://github.com/rojasirvin) [<i class="fab fa-twitter"></i>](https://twitter.com/RojasIrvin) [<i class="ai ai-google-scholar"></i>](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&hl=en)
]

---
# Agenda
  
1. 

---

class: inverse, middle, center

Estimador de MCO

---

# Modelo bivariado

Estamos interesados en estimar los parámetros poblacionales de un modelo de regresión lineal

$$y=\beta_0+\beta_1 x +u$$

En su primer cuso de econometría encontraron que

$$\hat{\beta_0}=\bar{y}-\hat{\beta_1}\bar{x}$$
$$\hat{\beta_1}=\frac{Cov(x,y)}{Var(x)}$$
---

# Modelo bivariado

Basta con calcular los ingredientes

```{r,echo=T,collapse=T, out.width="70%", warning=F, message=F, tidy=T}
setwd("C:/Users/Irvin/Dropbox/Ejercicios en R/datos/")

data.mlb <- read_csv(file = "./salarios_mlb.csv",
                    locale = locale(encoding = "latin1")) %>% 
  mutate(salary=exp(lsalary))


b1 <- cov(data.mlb$salary,data.mlb$hmrun)/var(data.mlb$hmrun)
b0 <- mean(data.mlb$salary)-mean(data.mlb$hmrun)*b1

b1
b0
```
---

# lm()

.pull-left[
La forma corta de hacer esto en R es usando la función *lm()*

¿Cómo se interpreta $\beta_0$ y $\beta_1$?

]

.pull-right[
```{r,echo=T,collapse=T, out.width="70%", tidy=T}
summary(res1<-lm(data=data.mlb, salary ~ hmrun))
```
]


---

# Modelo bivariado

.pull-left[
Gráficamente, el problema de MCO se puede representar de la siguiente forma
]

.pull-right[
```{r,echo=T,collapse=T, out.width="75%"}
data.mlb %>%
  ggplot(aes(x=hmrun,y=salary))+
  geom_point()+
  geom_smooth(method="lm")
```
]


---

# Bondad de ajuste

Sabemos que una médida de la bonda de ajuste del modelo es $R^2$

$$R^2=\frac{SCR}{SCT}=1-\frac{SCE}{SCT}$$

Nos dice cuánto de la variación en $y$ es explicada por la regresión, $SCR$

```{r,echo=T,collapse=T, out.width="75%"}
summary(res1)$r.squared
```


---

# Regresión con logaritmos

Si tenemos un modelo de la forma

$$log(y)=\beta_0+\beta_1 x +u$$
¿Cómo se interpreta $\beta_1$?

--

En su curso de econometría mostraron que en este caso

$$\frac{dy}{dx}=\beta_1 y$$

Así, el coeficiente tiene una interpretación de semielasticidad

Un cambio en una unidad de $x$ se asocia con un cambio de $100\beta_1$ porciento en $y$

---

# Modelo log-lineal

```{r,echo=T,collapse=T, out.width="70%"}
(res2 <- lm(data=data.mlb, lsalary ~ hmrun))
```
--

¿Qué significan estos resultados?


---

# Ejercicio 1

1. Estime ahora un modelo log-log

1. Deberá crear una variable que indique el log del número de home runs

1. ¿Cómo se interpreta $\beta_1$ en este modelo



---

# Modelo multivariado

.pull-left[
La extensión natural del modelo bivariado es el modelo multivariado, donde tenemos $K$ regresores o variables explicativas

$$log(y)=\beta_0+\beta_1 x_1 + \beta_2 x_2 + \ldots+\beta_K X_K +u$$


La interpretación de los coeficientes individuales es la misma que en el modelo bivariado


]

.pull-right[
```{r,echo=T,collapse=T, out.width="70%"}
summary(res3 <- lm(data=data.mlb,
                   lsalary ~ hmrun+years+atbat))

```
]

---

# Modelos con polinomios


.pull-left[
Podemos introducir regresores en forma de polinomios para describir mejor a los datos

$$log(salario)=\beta_0+\beta_1 homeruns + \beta_2 homeruns^2 +u$$

Noten que usamos la notiación *I()* para indicar que la variable dentro del paréntesis se eleva a cierta potencia

]

.pull-right[
```{r,echo=T,collapse=T, out.width="70%"}
res4 <- lm(data=data.mlb, lsalary ~ hmrun+I(hmrun^2)) 
summary(res4)
```
]

---

class: inverse, middle, center

# Pruebas de hipótesis

---

# Prueba $t$

Además del signo y la magnitud de los coeficientes de regresión, siempre ponemos atención al estadístico $t$ estimado

Nos interesa probar la hipótesis de que un coeficiente es igual a cierto número

Formulamos lo que conocemos como **hipótesis nula**:

$$H_0: \beta_j=a_j$$
Si la $H_0$ no se cumple, entonces:

- Para una prueba de dos colas, favorecemos la **hipótesis alternativa** $H_a=\beta_j\neq a_j$

- Para una prueba de una cola, favorecemos $H_a: \beta_j<a_j$ o que $H_a:\beta_j>a_j$

---

# Estadístico $t$

Si la $H_0$ es verdadera, tenemos el siguiente resultado:

$$t=\frac{\beta_j-a_j}{se(\beta_j)}\sim t(n-k-1)$$
$n-k-1$ son los grados de libertad

---

# Coeficientes de regresión

Frecuentemente queremos probar que $H: \beta_j=0$

En este caso, el estadístico $t$ es

$$t_{\hat{\beta}_j}=\frac{\hat{\beta}_j}{se(\hat{\beta}_j)}$$
---

# Nivel de significancia

El nivel de significancia $\alpha$ es la probabilidad de rechazar una hipótesis nula dado que esta es correcta

En economía usamos frecuentemente $\alpha=0.05$, es decir, que tenemos el riesgo de que 5% de las veces que rechacemos la hipótesis nula en realidad no deberíamos rechazarla

Es un parámetro escogido por el econometrista

---

# Regla de decisión

Nosotros sabemos qué valores en la distribución teórica $t(n-k-1)$ ocurren con una probabilidad mayor que $\alpha$ y qué valores son muy poco probables

El valor crítico $c$ nos corta los valores entre aquellos que son 95% o más probables de ver y los que son 5% o menos probables de ver

Si el estadístico $t_{\hat{\beta}_j}$ es más grande que $c$, es decir, es poco común bajo la $H_0$, tenemos evidencia para rechazarla

Para valores de grados de libertad lo suficientemente grandes, el valor crítico es muy cercado a 2

De aquí viene nuestra *regla de dedo* de decir que un coeficiente es estadísticamente significativo, a un nivel de significancia de 5%, cuando su estadístico $t$ asociado es mayor que 2

---

# Valor $p$

El valor $p$ es el número más pequeño de $\alpha$ para el que aún rechazaríamos $H_0$

Valores $p$ muy grandes, por ejemplo 25%, indicarían que rechacemos $H_0$ solo si estamos dispuestos a cometer el error de rechazar hasta 25% de las $H_0$ verdaderas


---

# Intuición de las pruebas de hipótesis

Todas las pruebas de hipótesis tienen la misma intuición

- Tenemos una $H_0$ que queremos probar
- Construimos un estadístico del que podemos conocer sus propiedades teóricas
- Fijamos $\alpha$
- Queremos determinar qué tan probable es ver la magnitud del estadístico bajo la $H_0$
- Si esta probabilidad es pequeña, rechazamos $H_0$

El valor $p$ y la magnitud del estadístico $t$ son dos caras de la misma moneda

Valores $p$ muy pequeños indican una probabilidad muy pequeña de rechazar $H_0$ que son ciertas y, por tanto, el valor del estadístico $t$ indicará que es muy poco probable ver dicha magnitud bajo la $H_0$

---

# Intervalos de confianza

Los intervalos de confianza definen una región (un rango de valores) dentro de los cuales esperaríamos que estuviera el valor verdadero de $\beta_j$

Un intervalo de confianza de 95% indica que, si tuviéramos acceso a repetidas muestras de la misma población, 95% de los intervalos de confianza contendrían al valor verdadero de $\beta_j$


--

class: inverse, center, middle
  
# Distibución asintótica de $\beta_{MCO}$

---

# Consistencia

- Consideremos el proceso generador de datos $y=X\beta+$

$$
\begin{aligned}
\hat{\beta}_{MCO}&=(X'X)^{-1}X'Y \\
&=(X'X)^{-1}X'(X\beta + u) \\
&=(X'X)^{-1}X'X\beta+(X'X)^{-1}X'U \\
&=\beta+(X'X)^{-1}X'u
\end{aligned}
$$

- Reescalando:

$$\hat{\beta}_{MCO}=\beta+(N^{-1}X'X)^{-1}N^{-1}X'u$$
- Noten que $N^{-1}X'X=N^{-1}\sum_{i=1}{N}x_ix_i'$ es un promedio

- Si  $x_ix_i'$ permite aplicar una LGN, entonces el promedio converge en probabilidad a una matriz finita distinta de $\mathbf{0}$

---

# Consistencia

- Si una LGN puede aplicarse, entonces usando el Teorema de Slutsky:

$$p\lim \hat{\beta}_{MCO}=\beta+(p\lim N^{-1}X'X)^{-1}(p\lim N^{-1}X'u)$$


- Entonces $\beta_{MCO}$ es consistente para $\beta$, es decir, $p\lim\hat{\beta}_{MCO}=\beta$ si $p\lim N^{-1}X'u=0$

- Si se puede aplicar una LGN al promedio $N^{-1}X'u=N^{-1}\sum_ix_iu_i$ , una condición necesaria es que $E(x_iu_i)=0$

- Esta es la condición sobre los errores que enumerábamos en nuestra lista de supuestos en los cursos básicos de econometría

---

# Distribución límite

- Dada la consistencia del estimador de MCO,la distribución límite de $\beta_{MCO}$ tiene toda su masa en $\beta$

- Podemos reescalar multiplicando por $\sqrt{N}$, lo que nos permite obtener una variable aleatoria con varianza distinta de cero y asintóticamente finita:

$$\sqrt{N}(\hat{\beta}_{MCO}-\beta)=(N^{-1}X'X)^{-1}N^{-1/2}X'u$$

- Sabemos que $p\lim(N^{-1}X'X)$ existe y es una matriz finida distinta de $\mathbf{0}$

- Si se puede aplicar un TLC, $N^{-1/2}X'u$ tendrá una distribución con matriz de covarianzas no singular y finita

- Por la regla del límite normal del producto $(N^{-1}X'X)^{-1}N^{-1/2}X'u$ tendrá una distribución límite normal

---

# Distribución del estimador de MCO

- Supuestos:
  1. El proceso generador de datos es $y=X\beta+u$
  1. Los datos son independientes entre $i$, $E(u|X)=0$ y $E(uu'|X)=\Omega=Diag(\sigma_i^2)$
  1. $X$ es de rango completo
  1. La matriz $M_{XX}=p\lim N^{-1}X'X=\lim\sum_iE(x_ix_i')$ existe y es finita y no singular
  1. El vector $N^{-1/2}X'u\xrightarrow{d}\mathcal{N}(0,M_{X\Omega X})$, donde
  $$M_{X\Omega X}=p\lim N^{-1}X'uu'X=\lim N^{-1}\sum_iE(u_i^2x_ix_i')$$
  
- Entonces $\hat{\beta}_{MCO}$ es consitente para $\beta$ y la *distribución limite* de $\sqrt{N}(\hat{\beta}_{MCO}-\beta)$ es

$$\sqrt{N}(\hat{\beta}_{MCO}-\beta)\xrightarrow{d}\mathcal{N}(0,M_{XX}^{-1}M_{X\Omega X}M_{XX}^{-1})$$

---

# Distribución asintótica del estimador de MCO

- Podemos expresar el resultado en términos de  $\hat{\beta}_{MCO}$ dividiendo por $\sqrt{N}$ y sumando $\beta$:

$$\hat{\beta}_{MCO} \stackrel{a}{\sim} \mathcal{N}(\beta,N^{-1}M_{XX}^{-1}M_{X\Omega X}M_{XX}^{-1})$$

- A la matriz $V(\hat{\beta})=N^{-1}M_{XX}^{-1}M_{X\Omega X}M_{XX}^{-1}$ es la *matriz de varianza asintótica*

- Eliminado los límites y las expectativas, una forma más compacta de escribit la distribución del estimador de MCO es

$$\hat{\beta}_{MCO} \stackrel{a}{\sim} \mathcal{N}(\beta,(X'X)^{-1}X'\Omega X (X'X)^{-1})$$

- En la práctica, reemplazamos $M_{XX}$ y $M_{X\Omega X}$ por estimadores consistentes para obtener la *matriz estimada de la varianza asintótica*:

$$\hat{V}(\hat{\beta})=N^{-1}\hat{M}_{XX}^{-1}\hat{M}_{X\Omega X}\hat{M}_{XX}^{-1}$$

---

# El estimador de *sándwich*

- Frecuentemente nos toparemos con el estimador de la varianza de *sándwich* del tipo $\hat{M}_{XX}^{-1}\hat{M}_{X\Omega X}\hat{M}_{XX}^{-1}$

- Un estimador para $\hat{M}_{XX}$ es $N^{-1}X'X$

- El estimador de $\hat{M}_{M\Omega M}$ depende de lo que asumamos de los errores

- En los primeros cursos de econometría se asumen errores homocedásticos tales que $\Omega=\sigma^2I$, por lo que:

$$\hat{V}(\hat{\beta}_{MCO,iid})=\hat{s}^2(X'X)^{-1}$$

- Con errores heterocedásticos, es decir, que dependen de $X_i$, la v

- Pero si $V(u_i|x_i)=E(u_i^2|x_i)=\sigma_i^2$, es decir, los errores varían con $i$, White (1980) propone usar como estimador de la varianza a $\hat{M}_{X\Omega X}=N^{-1}\sum_i \hat{u}_i^2x_ix_i'$, dando lugar a:


---

# Próxima sesión

- Estudiaremos la violación al supuesto de errores ortogonales

- Estudiaremos el uso de variables instrumentales para resolver el problema de endogeneidad

---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**